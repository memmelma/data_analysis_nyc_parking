{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Issue Date\n",
    "\n",
    "Hier werden die Daten nun für das Umsetzen in verschieden Graphiken angepasst.\n",
    "Dafür werden nun zunächst einige Variablen sowie Funktion deklariert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ready!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import feather as fth\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "\n",
    "datadir = '../../data/nyc_parking_tickets/'\n",
    "numdatadir='../../data/nyc_parking_tickets/NumericAnalysis/'\n",
    "sumtodatedir ='../../data/nyc_parking_tickets/NumericAnalysis/SumToDate/'\n",
    "sumtomonthdir ='../../data/nyc_parking_tickets/NumericAnalysis/SumToMonth/'\n",
    "\n",
    "# sum the data to each specific date thats give\n",
    "def numericanalysisprocessing(data):\n",
    "    numericdata = data.groupby(['Issue Date']).size().reset_index().rename(columns={0:'count'})\n",
    "    return numericdata\n",
    "\n",
    "print('all ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Schritt\n",
    "\n",
    "Für jedes Jahr werden nun die Daten Chunkweise eingelesen. Es wird lediglich das Datum des jeweiligen Vorfalls eingelesen, in das Datumframt von Pandas umgewandelt.\n",
    "Danach werden alle Daten, die nicht innerhalb dieses Fiskaljahres liegen aus der Datei entfernt. Beispiel das Fiskaljahr 2017 in den USA ging vom 1.10.2016 bis zum 30.09.2017.\n",
    "\n",
    "Nun werden die einzelnen Datein aus dem Unterordner einzelnd eingelesen und für die Graphen, in denen jedes einzelne Datum dargelegt wird, aufbereitet.\n",
    "Anschließend wird die Datei sortiert und in einem Unterordner abgelegt.\n",
    "\n",
    "## 2.Schritt\n",
    "\n",
    "Hier werden nun die Daten auch Chunkweise eingelesen. Hier werden nun jedoch alle Daten immer auf den letzten ihres Monats umgemüntz. \n",
    "Anschließend wird wie beim vorherigen Step die Daten bereinigt, sortiert und aufsummiert.\n",
    "\n",
    "\n",
    "### Jahr 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 10900000\n",
      "data loaded\n",
      "data is sorted\n",
      "data cleared up\n",
      "data is saved \n"
     ]
    }
   ],
   "source": [
    "# 1.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2017'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2016-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2017-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtodatedir +'SumToDate_2017'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 10900000\n",
      "data loaded\n",
      "data is sorted\n",
      "data cleared up\n",
      "data sum up to month\n",
      "data is saved \n"
     ]
    }
   ],
   "source": [
    "# 2.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2017'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        chunk['Issue Date'] = chunk['Issue Date'].map(\n",
    "                        lambda x: datetime.datetime(\n",
    "                        x.year,\n",
    "                        x.month,\n",
    "                        max(calendar.monthcalendar(x.year, x.month)[-1][:5])\n",
    "                    )\n",
    "              )\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2016-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2017-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "print('data sum up to month')\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtomonthdir +'SumToMonth_2017'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jahr 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 10700000\n",
      "data loaded\n",
      "data is sorted\n",
      "data cleared up\n",
      "data is saved \n"
     ]
    }
   ],
   "source": [
    "#1.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2016'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2015-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2016-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtodatedir +'SumToDate_2016'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Up completed\n"
     ]
    }
   ],
   "source": [
    "# 2.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2017'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        chunk['Issue Date'] = chunk['Issue Date'].map(\n",
    "                        lambda x: datetime.datetime(\n",
    "                        x.year,\n",
    "                        x.month,\n",
    "                        max(calendar.monthcalendar(x.year, x.month)[-1][:5])\n",
    "                    )\n",
    "              )\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2015-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2016-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "print('data sum up to month')\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtomonthdir +'SumToMonth_2016'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jahr 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 11900000\n",
      "data loaded\n",
      "data is sorted\n",
      "data cleared up\n",
      "data is saved \n"
     ]
    }
   ],
   "source": [
    "#1.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2015'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2014-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2015-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtodatedir +'SumToDate_2015'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Up completed\n"
     ]
    }
   ],
   "source": [
    "# 2.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2017'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        chunk['Issue Date'] = chunk['Issue Date'].map(\n",
    "                        lambda x: datetime.datetime(\n",
    "                        x.year,\n",
    "                        x.month,\n",
    "                        max(calendar.monthcalendar(x.year, x.month)[-1][:5])\n",
    "                    )\n",
    "              )\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2014-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2015-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "print('data sum up to month')\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtomonthdir +'SumToMonth_2015'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jahr 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 9200000\n",
      "data loaded\n",
      "data is sorted\n",
      "data cleared up\n",
      "data is saved \n"
     ]
    }
   ],
   "source": [
    "#1.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2013-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2014-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtodatedir +'SumToDate_2014'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Up completed\n"
     ]
    }
   ],
   "source": [
    "# 2.Schritt\n",
    "file = 'Parking_Violations_Issued_-_Fiscal_Year_2017'\n",
    "path = datadir + file + '.csv'\n",
    "\n",
    "cols = ['Issue Date']\n",
    "dtype = {'Issue Date': object}\n",
    "csize =100000\n",
    "data =pd.DataFrame()\n",
    "readcount =0\n",
    "\n",
    "reader = pd.read_csv(path, chunksize = csize, sep=',' ,usecols=cols, dtype=dtype)\n",
    "\n",
    "for chunk in reader:\n",
    "        chunk['Issue Date'] =pd.to_datetime(chunk['Issue Date'])\n",
    "        chunk['Issue Date'] = chunk['Issue Date'].map(\n",
    "                        lambda x: datetime.datetime(\n",
    "                        x.year,\n",
    "                        x.month,\n",
    "                        max(calendar.monthcalendar(x.year, x.month)[-1][:5])\n",
    "                    )\n",
    "              )\n",
    "        data =pd.concat([data, chunk])\n",
    "        readcount = readcount+csize\n",
    "        print('Read: '+str(readcount), end='\\r')\n",
    "print('Read: '+str(readcount))\n",
    "print('data loaded')\n",
    "data = data.sort_values(by='Issue Date')\n",
    "print ('data is sorted')\n",
    "data = data[~(data['Issue Date'] <'2013-10-01')] # low border \n",
    "data = data[~(data['Issue Date'] >'2014-09-30')] # high border\n",
    "print('data cleared up')\n",
    "data = numericanalysisprocessing(data)\n",
    "print('data sum up to month')\n",
    "#save data \n",
    "fth.write_dataframe(data, sumtomonthdir +'SumToMonth_2014'+'.fth')\n",
    "print('data is saved ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die einzelnen Dateien werden nun noch zusammengefügt um einen Graphen über die gesammte Zeit darstellen zu können\n",
    "\n",
    "Zuerst für jeden einzelen Tag und dannach noch einmal Monatsweise aneinandergehängt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat completed\n"
     ]
    }
   ],
   "source": [
    "# pro day\n",
    "file2017 ='SumToDate_2017.fth'\n",
    "file2016 ='SumToDate_2016.fth'\n",
    "file2015 ='SumToDate_2015.fth'\n",
    "file2014 ='SumToDate_2014.fth'\n",
    "\n",
    "path2017 = sumtodatedir+file2017\n",
    "path2016 = sumtodatedir+file2016\n",
    "path2015 = sumtodatedir+file2015\n",
    "path2014 = sumtodatedir+file2014\n",
    "\n",
    "data2017 = fth.read_dataframe(path2017)\n",
    "data2016 = fth.read_dataframe(path2016)\n",
    "data2015 = fth.read_dataframe(path2015)\n",
    "data2014 = fth.read_dataframe(path2014)\n",
    "\n",
    "data = pd.concat([data2014,data2015,data2016,data2017])\n",
    "fth.write_dataframe(data, sumtodatedir+'SumToDate_AllTime'+'.fth')\n",
    "print('concat completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per month\n",
    "file2017 ='SumToMonth_2017.fth'\n",
    "file2016 ='SumToMonth_2016.fth'\n",
    "file2015 ='SumToMonth_2015.fth'\n",
    "file2014 ='SumToMonth_2014.fth'\n",
    "\n",
    "path2017 = sumtodatedir+file2017\n",
    "path2016 = sumtodatedir+file2016\n",
    "path2015 = sumtodatedir+file2015\n",
    "path2014 = sumtodatedir+file2014\n",
    "\n",
    "data2017 = fth.read_dataframe(path2017)\n",
    "data2016 = fth.read_dataframe(path2016)\n",
    "data2015 = fth.read_dataframe(path2015)\n",
    "data2014 = fth.read_dataframe(path2014)\n",
    "\n",
    "data = pd.concat([data2014,data2015,data2016,data2017])\n",
    "fth.write_dataframe(data, sumtomonthdir+'SumToMonth_AllTime'+'.fth')\n",
    "print('concat completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
